{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.2.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\angel\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\angel\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\angel\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\angel\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\angel\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\angel\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.2.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\angel\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\angel\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\angel\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\angel\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\angel\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install pandas numpy scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_check(data, target):\n",
    "    try:\n",
    "        df = pd.read_csv(data)\n",
    "    except:\n",
    "        print(\"Error Reading cannot be found\")\n",
    "        return\n",
    "\n",
    "    #now check value counts\n",
    "    ones_percentage = df[target].value_counts(normalize=True).loc[1] * 100\n",
    "    print(f\"Percentage of 1s for : {ones_percentage:.2f}%\")\n",
    "\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 1s for : 9.58%\n",
      "Percentage of 1s for : 1.00%\n",
      "Percentage of 1s for : 5.29%\n",
      "Percentage of 1s for : 0.30%\n",
      "Percentage of 1s for : 4.94%\n",
      "Percentage of 1s for : 0.88%\n"
     ]
    }
   ],
   "source": [
    "balance_check(\"data/train.csv/train.csv\",\"toxic\")\n",
    "balance_check(\"data/train.csv/train.csv\",\"severe_toxic\")\n",
    "balance_check(\"data/train.csv/train.csv\",\"obscene\")\n",
    "balance_check(\"data/train.csv/train.csv\",\"threat\")\n",
    "balance_check(\"data/train.csv/train.csv\",\"insult\")\n",
    "balance_check(\"data/train.csv/train.csv\",\"identity_hate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"data/train.csv/train.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cpu\n",
      "Requirement already satisfied: torch in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.8.0.dev20250413+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.22.0.dev20250413+cpu)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.6.0.dev20250413+cpu)\n",
      "Requirement already satisfied: filelock in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\angel\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\angel\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\angel\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\angel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install nltk\n",
    "\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "\n",
    "%pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Toxic Comment Classification Pipeline\n",
      "Dataset loaded successfully!\n",
      "Shape: (159571, 8)\n",
      "\n",
      "Null values per column:\n",
      "id               0\n",
      "comment_text     0\n",
      "toxic            0\n",
      "severe_toxic     0\n",
      "obscene          0\n",
      "threat           0\n",
      "insult           0\n",
      "identity_hate    0\n",
      "dtype: int64\n",
      "\n",
      "Text processing examples:\n",
      "\n",
      "Original 0:\n",
      "Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "\n",
      "Processed:\n",
      "explanation why the edits made under my username hardcore metallica fan were reverted? they weren't vandalisms just closure on some gas after i voted at new york dolls fac. and please don't remove the template from the talk page since i'm retired now.\n",
      "--------------------------------------------------\n",
      "\n",
      "Original 1:\n",
      "D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
      "\n",
      "Processed:\n",
      "d'aww! he matches this background colour i'm seemingly stuck with. thanks. talk 21 51 january 11 2016 utc\n",
      "--------------------------------------------------\n",
      "\n",
      "Original 2:\n",
      "Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\n",
      "\n",
      "Processed:\n",
      "hey man i'm really not trying to edit war. it's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. he seems to care more about the formatting than the actual info.\n",
      "--------------------------------------------------\n",
      "\n",
      "Initializing BERT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\angel\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT initialized successfully\n",
      "\n",
      "Tokenization example:\n",
      "\n",
      "Sample text: explanation why the edits made under my username hardcore metallica fan were reverted? they weren't vandalisms just closure on some gas after i voted at new york dolls fac. and please don't remove the template from the talk page since i'm retired now.\n",
      "\n",
      "Tokens: ['explanation', 'why', 'the', 'edit', '##s', 'made', 'under', 'my', 'user', '##name', 'hardcore', 'metallic', '##a', 'fan', 'were', 'reverted', '?', 'they', 'weren', \"'\", 't', 'van', '##dal', '##isms', 'just', 'closure', 'on', 'some', 'gas', 'after', 'i', 'voted', 'at', 'new', 'york', 'dolls', 'fa', '##c', '.', 'and', 'please', 'don', \"'\", 't', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'i', \"'\", 'm', 'retired', 'now', '.']\n",
      "\n",
      "Token IDs: [101, 7526, 2339, 1996, 10086, 2015, 2081, 2104, 2026, 5310, 18442, 13076, 12392, 2050, 5470, 2020, 16407, 1029, 2027, 4694, 1005, 1056, 3158, 9305, 22556, 2074, 8503, 2006, 2070, 3806, 2044, 1045, 5444, 2012, 2047, 2259, 14421, 6904, 2278, 1012, 1998, 3531, 2123, 1005, 1056, 6366, 1996, 23561, 2013, 1996, 2831, 3931, 2144, 1045, 1005, 1049, 3394, 2085, 1012, 102]\n",
      "\n",
      "Pipeline execution complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ NLTK Fix for LookupError\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# Dynamically resolve the user's nltk_data path\n",
    "nltk_path = os.path.join(os.path.expanduser('~'), 'AppData', 'Roaming', 'nltk_data')\n",
    "if nltk_path not in nltk.data.path:\n",
    "    nltk.data.path.append(nltk_path)\n",
    "\n",
    "# Trigger a preload of stopwords to catch missing resource issues early\n",
    "try:\n",
    "    _ = stopwords.words('english')\n",
    "except LookupError as e:\n",
    "    print(\"NLTK stopwords resource not found, attempting to download again...\")\n",
    "    nltk.download('stopwords')\n",
    "    _ = stopwords.words('english')\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        print(\"Dataset loaded successfully!\")\n",
    "        print(f\"Shape: {df.shape}\")\n",
    "\n",
    "        # check for null values\n",
    "        print(\"\\nNull values per column:\")\n",
    "        print(df.isnull().sum())\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # remove artifacts and wikimarkups\n",
    "    text = re.sub(r'==.*?==+', '', text)\n",
    "    text = re.sub(r'\\[\\[.*?\\]\\]', '', text)\n",
    "    text = re.sub(r'\\{\\{.*?\\}\\}', '', text)\n",
    "    text = re.sub(r'__[A-Z]+__', '', text)\n",
    "    text = re.sub(r'&[a-z]+;', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # URLs, IPs, timestamps, extra spaces, and lowercasing\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', '', text)\n",
    "    text = re.sub(r'\\d{1,2}:\\d{2},?\\s*\\d{1,2}\\s+\\w+\\s+\\d{4}', '', text)\n",
    "    text = re.sub(r\"[^\\w\\s'!?.]\", ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    try:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        custom_stopwords = {\n",
    "            'wikipedia', 'page', 'article', 'edit', 'user', 'talk',\n",
    "            'section', 'redirect', 'category', 'file', 'image', 'template'\n",
    "        }\n",
    "        stop_words.update(custom_stopwords)\n",
    "\n",
    "        negation_words = {\n",
    "            'not', 'no', 'never', 'none', 'nor', 'neither',\n",
    "            \"don't\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\",\n",
    "            \"haven't\", \"hasn't\", \"hadn't\", \"won't\", \"wouldn't\"\n",
    "        }\n",
    "        stop_words -= negation_words\n",
    "\n",
    "        tokens = word_tokenize(text)\n",
    "        filtered_tokens = [\n",
    "            word for word in tokens \n",
    "            if word not in stop_words and len(word) > 2 and not word.startswith(\"'\")\n",
    "        ]\n",
    "\n",
    "        return ' '.join(filtered_tokens)\n",
    "    except LookupError as e:\n",
    "        if \"stopwords\" in str(e) or \"punkt\" in str(e):\n",
    "            nltk.download('punkt', quiet=True)\n",
    "            nltk.download('stopwords', quiet=True)\n",
    "            try:\n",
    "                stop_words = set(stopwords.words('english'))\n",
    "                tokens = word_tokenize(text)\n",
    "                return ' '.join(tokens)  # fallback: just tokenize\n",
    "            except Exception:\n",
    "                return text  # worst case: return raw text\n",
    "        return text\n",
    "\n",
    "def initialize_bert():\n",
    "    print(\"\\nInitializing BERT model...\")\n",
    "    try:\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        model = BertModel.from_pretrained('bert-base-uncased')\n",
    "        print(\"BERT initialized successfully\")\n",
    "        return tokenizer, model\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing BERT: {e}\")\n",
    "        return None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    FILE_PATH = \"data/train.csv/train.csv\"\n",
    "\n",
    "    print(\"Starting Toxic Comment Classification Pipeline\")\n",
    "    df = load_dataset(FILE_PATH)\n",
    "\n",
    "    if df is not None:\n",
    "        df['cleaned_text'] = df['comment_text'].apply(clean_text)\n",
    "        df['processed_text'] = df['cleaned_text'].apply(remove_stopwords)\n",
    "\n",
    "        # show some examples of cleaning\n",
    "        print(\"\\nText processing examples:\")\n",
    "        for i in range(3):\n",
    "            print(f\"\\nOriginal {i}:\")\n",
    "            print(df['comment_text'].iloc[i])\n",
    "            print(\"\\nProcessed:\")\n",
    "            print(df['processed_text'].iloc[i])\n",
    "            print(\"-\"*50)\n",
    "\n",
    "        bert_tokenizer, bert_model = initialize_bert()\n",
    "\n",
    "        if bert_tokenizer:\n",
    "            print(\"\\nTokenization example:\")\n",
    "            sample_text = df['processed_text'].iloc[0]\n",
    "            print(f\"\\nSample text: {sample_text}\")\n",
    "\n",
    "            tokens = bert_tokenizer.tokenize(sample_text)\n",
    "            print(f\"\\nTokens: {tokens}\")\n",
    "\n",
    "            token_ids = bert_tokenizer.encode(sample_text, add_special_tokens=True)\n",
    "            print(f\"\\nToken IDs: {token_ids}\")\n",
    "\n",
    "    print(\"\\nPipeline execution complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    df['cleaned_text'] = df['comment_text'].apply(clean_text)\n",
    "    df['processed_text'] = df['cleaned_text'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/159571 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [3:47:46<00:00, 11.68it/s]  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def get_bert_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]  # Use [CLS] token\n",
    "    return cls_embedding.squeeze().numpy()\n",
    "\n",
    "df['bert_embedding'] = df['processed_text'].progress_apply(\n",
    "    lambda x: get_bert_embedding(x, bert_tokenizer, bert_model)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
